{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2e622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best_params.json with 16 models:\n",
      "   • DecisionTreeClassifier\n",
      "   • RandomForestClassifier\n",
      "   • ExtraTreesClassifier\n",
      "   • GradientBoostingClassifier\n",
      "   • AdaBoostClassifier\n",
      "   • XGBClassifier\n",
      "   • LogisticRegression\n",
      "   • RidgeClassifier\n",
      "   • SGDClassifier\n",
      "   • Perceptron\n",
      "   • KNeighborsClassifier\n",
      "   • SVC\n",
      "   • GaussianNB\n",
      "   • LinearDiscriminantAnalysis\n",
      "   • QuadraticDiscriminantAnalysis\n",
      "   • MLPClassifier\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# 1. LOAD TUNED PARAMETERS\n",
    "# -------------------------------------------\n",
    "\n",
    "# Module 06_build_model_dict.ipynb:\n",
    "#   Load best_params.json (output from module 05) \n",
    "#   Dynamically import model classes using AVAILABLE_MODELS for class/module mapping\n",
    "#   Instantiate all 16 models with: \n",
    "#   -- best parameters (from JSON)\n",
    "#   -- default parameters if model was not tuned (e.g., GaussianNB)\n",
    "\n",
    "\n",
    "import json\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from sklearn.base import BaseEstimator\n",
    "import warnings\n",
    "import joblib\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore all warnings for cleaner output. Hypertuning has many warnings.\n",
    "\n",
    "# Define this project's file locations.\n",
    "# This notebook uses a centralized config.py file for all path management.\n",
    "\n",
    "# Import config paths\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from config import TUNED_MODELS_DIR, MODEL_DICT_PATH\n",
    "\n",
    "# Define this project's paths to retrieve and save files. \n",
    "tuned_models_dir = TUNED_MODELS_DIR\n",
    "model_dict = joblib.load(MODEL_DICT_PATH)\n",
    "\n",
    "\n",
    "# Load tuning results (the winners from GridSearchCV runs)\n",
    "best_params_path = TUNED_MODELS_DIR / \"best_params.json\"\n",
    "with open(best_params_path, \"r\") as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "# Confirm full list of models are loaded\n",
    "print(f\"Loaded best_params.json with {len(best_params)} models:\")\n",
    "for model in best_params.keys():\n",
    "    print(f\"   • {model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1362547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 2. DEFINE AVAILABLE_MODELS METADATA\n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "#  The .json file contains only the winning parameter values, not the metadata needed to instantiate models.\n",
    "#  Therefore, this cell provides the metadata needed to build (instantiate) each model.\n",
    "\n",
    "#  AVAILABLE_MODELS defines the metadata. It documents how to find and instantiate each model, with:\n",
    "#  -- \"class\":  the model class name to use\n",
    "#  -- \"module\":  the module path to import from\n",
    "#  Must use the same AVAILABLE_MODELS structure as in module 05_tune_hyperparameters.ipynb for \n",
    "#  the instantiation of each model from .json best parameters file to work correctly in this module.\n",
    "#  AVAILABLE_MODELS provides the \"how to build\" instructions for each model.\n",
    "\n",
    "\n",
    "AVAILABLE_MODELS = {\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"class\": \"DecisionTreeClassifier\",\n",
    "        \"module\": \"sklearn.tree\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"random_state\": 42},\n",
    "        \"param_grid\": {\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "            \"max_depth\": [None, 5, 10, 20],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "            \"min_samples_leaf\": [1, 3]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"class\": \"RandomForestClassifier\",\n",
    "        \"module\": \"sklearn.ensemble\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"random_state\": 42, \"n_jobs\": -1},\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [50, 100],\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "            \"min_samples_leaf\": [1, 3]\n",
    "        }\n",
    "    },\n",
    "    \"ExtraTreesClassifier\": {\n",
    "        \"class\": \"ExtraTreesClassifier\",\n",
    "        \"module\": \"sklearn.ensemble\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"random_state\": 42, \"n_jobs\": -1},\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [50, 100],\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5]\n",
    "        }\n",
    "    },\n",
    "    \"GradientBoostingClassifier\": {\n",
    "        \"class\": \"GradientBoostingClassifier\",\n",
    "        \"module\": \"sklearn.ensemble\",\n",
    "        \"subsample\": 0.8,\n",
    "        \"max_depth\": 5,\n",
    "        \"max_features\": \"sqrt\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"random_state\": 42, \"subsample\": 0.8,\n",
    "            \"max_depth\": 5,\n",
    "            \"max_features\": \"sqrt\"\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [50, 100],\n",
    "            \"learning_rate\": [0.05, 0.1],\n",
    "            \"max_depth\": [3, 5]\n",
    "        }\n",
    "    },\n",
    "    \"AdaBoostClassifier\": {\n",
    "        \"class\": \"AdaBoostClassifier\",\n",
    "        \"module\": \"sklearn.ensemble\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"random_state\": 42},\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [50, 100],\n",
    "            \"learning_rate\": [0.5, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \"XGBClassifier\": {\n",
    "        \"class\": \"XGBClassifier\",\n",
    "        \"module\": \"xgboost\",\n",
    "        \"requires_numeric_labels\": True,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"use_label_encoder\": False,\n",
    "            \"eval_metric\": \"mlogloss\",\n",
    "            \"n_jobs\": -1\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [50, 100],\n",
    "            \"max_depth\": [3, 6],\n",
    "            \"learning_rate\": [0.1, 0.2],\n",
    "            \"subsample\": [0.8, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"class\": \"LogisticRegression\",\n",
    "        \"module\": \"sklearn.linear_model\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"random_state\": 42, \"n_jobs\": -1, \"max_iter\": 1000},\n",
    "        \"param_grid\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"penalty\": [\"l2\"],\n",
    "            \"solver\": [\"lbfgs\", \"liblinear\"]\n",
    "        }\n",
    "    },\n",
    "    \"RidgeClassifier\": {\n",
    "        \"class\": \"RidgeClassifier\",\n",
    "        \"module\": \"sklearn.linear_model\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {},\n",
    "        \"param_grid\": {\n",
    "            \"alpha\": [0.1, 1.0, 10.0],\n",
    "            \"solver\": [\"auto\", \"sparse_cg\"]\n",
    "        }\n",
    "    },\n",
    "    \"SGDClassifier\": {\n",
    "        \"class\": \"SGDClassifier\",\n",
    "        \"module\": \"sklearn.linear_model\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"random_state\": 42, \"n_jobs\": -1},\n",
    "        \"param_grid\": {\n",
    "            \"loss\": [\"hinge\", \"log_loss\"],\n",
    "            \"alpha\": [0.0001, 0.001],\n",
    "            \"penalty\": [\"l2\", \"l1\"]\n",
    "        }\n",
    "    },\n",
    "    \"Perceptron\": {\n",
    "        \"class\": \"Perceptron\",\n",
    "        \"module\": \"sklearn.linear_model\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"random_state\": 42, \"max_iter\": 1000, \"n_jobs\": -1},\n",
    "        \"param_grid\": {\n",
    "            \"penalty\": [\"l2\", \"elasticnet\", None],\n",
    "            \"alpha\": [0.0001, 0.001]\n",
    "        }\n",
    "    },\n",
    "    \"KNeighborsClassifier\": {\n",
    "        \"class\": \"KNeighborsClassifier\",\n",
    "        \"module\": \"sklearn.neighbors\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"n_jobs\": -1},\n",
    "        \"param_grid\": {\n",
    "            \"n_neighbors\": [3, 5, 7],\n",
    "            \"weights\": [\"uniform\", \"distance\"],\n",
    "            \"metric\": [\"euclidean\", \"manhattan\"]\n",
    "        }\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"class\": \"SVC\",\n",
    "        \"module\": \"sklearn.svm\",\n",
    "        \"random_state\": 42,\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"random_state\": 42, \"probability\": True},\n",
    "        \"param_grid\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"kernel\": [\"linear\", \"rbf\"],\n",
    "            \"gamma\": [\"scale\", \"auto\"]\n",
    "        }\n",
    "    },\n",
    "    \"GaussianNB\": {\n",
    "        \"class\": \"GaussianNB\",\n",
    "        \"module\": \"sklearn.naive_bayes\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {},\n",
    "        \"param_grid\": {}\n",
    "    },\n",
    "    \"LinearDiscriminantAnalysis\": {\n",
    "        \"class\": \"LinearDiscriminantAnalysis\",\n",
    "        \"module\": \"sklearn.discriminant_analysis\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {},\n",
    "        \"param_grid\": {\n",
    "            \"solver\": [\"svd\", \"lsqr\"],\n",
    "            \"shrinkage\": [None, \"auto\"]\n",
    "        }\n",
    "    },\n",
    "    \"QuadraticDiscriminantAnalysis\": {\n",
    "    \"class\": \"QuadraticDiscriminantAnalysis\",\n",
    "    \"module\": \"sklearn.discriminant_analysis\",\n",
    "    \"requires_numeric_labels\": False,\n",
    "    \"search_type\": \"grid\",\n",
    "    \"scoring\": \"accuracy\",\n",
    "    \"default_params\": {},\n",
    "    \"param_grid\": {\n",
    "        \"reg_param\": [0.0, 0.1, 0.5]\n",
    "    }\n",
    "    },\n",
    "    \"MLPClassifier\": {\n",
    "        \"class\": \"MLPClassifier\",\n",
    "        \"module\": \"sklearn.neural_network\",\n",
    "        \"requires_numeric_labels\": True,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"random_state\": 42, \"max_iter\": 1000},\n",
    "        \"param_grid\": {\n",
    "            \"hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
    "            \"activation\": [\"relu\", \"tanh\"],\n",
    "            \"solver\": [\"adam\", \"lbfgs\"],\n",
    "            \"alpha\": [0.0001, 0.001, 0.01]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39748b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model_dict from best_params.json...\n",
      "\n",
      "DecisionTreeClassifier         | ✅ Tuned + default params used\n",
      "RandomForestClassifier         | ✅ Tuned + default params used\n",
      "ExtraTreesClassifier           | ✅ Tuned + default params used\n",
      "GradientBoostingClassifier     | ✅ Tuned + default params used\n",
      "AdaBoostClassifier             | ✅ Tuned + default params used\n",
      "XGBClassifier                  | ✅ Tuned + default params used\n",
      "LogisticRegression             | ✅ Tuned + default params used\n",
      "RidgeClassifier                | ✅ Tuned + default params used\n",
      "SGDClassifier                  | ✅ Tuned + default params used\n",
      "Perceptron                     | ✅ Tuned + default params used\n",
      "KNeighborsClassifier           | ✅ Tuned + default params used\n",
      "SVC                            | ✅ Tuned + default params used\n",
      "GaussianNB                     | ⚠️ Only default parameters used (no tuning found)\n",
      "LinearDiscriminantAnalysis     | ✅ Tuned + default params used\n",
      "QuadraticDiscriminantAnalysis  | ✅ Tuned + default params used\n",
      "MLPClassifier                  | ✅ Tuned + default params used\n",
      "\n",
      "model_dict created with the following keys:\n",
      "   DecisionTreeClassifier | RandomForestClassifier | ExtraTreesClassifier | GradientBoostingClassifier\n",
      "   AdaBoostClassifier | XGBClassifier | LogisticRegression | RidgeClassifier\n",
      "   SGDClassifier | Perceptron | KNeighborsClassifier | SVC\n",
      "   GaussianNB | LinearDiscriminantAnalysis | QuadraticDiscriminantAnalysis | MLPClassifier\n",
      "\n",
      "Confirm full constructor parameters for each model in model_dict:\n",
      "\n",
      "🧠 AdaBoostClassifier\n",
      "{'algorithm': 'deprecated',\n",
      " 'estimator': None,\n",
      " 'learning_rate': 1.0,\n",
      " 'n_estimators': 100,\n",
      " 'random_state': 42}\n",
      "------------------------------------------------------------\n",
      "🧠 DecisionTreeClassifier\n",
      "{'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': 10,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 5,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'monotonic_cst': None,\n",
      " 'random_state': 42,\n",
      " 'splitter': 'best'}\n",
      "------------------------------------------------------------\n",
      "🧠 ExtraTreesClassifier\n",
      "{'bootstrap': False,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'sqrt',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 5,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'monotonic_cst': None,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': -1,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "------------------------------------------------------------\n",
      "🧠 GaussianNB\n",
      "{'priors': None, 'var_smoothing': 1e-09}\n",
      "------------------------------------------------------------\n",
      "🧠 GradientBoostingClassifier\n",
      "{'ccp_alpha': 0.0,\n",
      " 'criterion': 'friedman_mse',\n",
      " 'init': None,\n",
      " 'learning_rate': 0.1,\n",
      " 'loss': 'log_loss',\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'sqrt',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_iter_no_change': None,\n",
      " 'random_state': 42,\n",
      " 'subsample': 0.8,\n",
      " 'tol': 0.0001,\n",
      " 'validation_fraction': 0.1,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "------------------------------------------------------------\n",
      "🧠 KNeighborsClassifier\n",
      "{'algorithm': 'auto',\n",
      " 'leaf_size': 30,\n",
      " 'metric': 'euclidean',\n",
      " 'metric_params': None,\n",
      " 'n_jobs': -1,\n",
      " 'n_neighbors': 7,\n",
      " 'p': 2,\n",
      " 'weights': 'distance'}\n",
      "------------------------------------------------------------\n",
      "🧠 LinearDiscriminantAnalysis\n",
      "{'covariance_estimator': None,\n",
      " 'n_components': None,\n",
      " 'priors': None,\n",
      " 'shrinkage': None,\n",
      " 'solver': 'svd',\n",
      " 'store_covariance': False,\n",
      " 'tol': 0.0001}\n",
      "------------------------------------------------------------\n",
      "🧠 LogisticRegression\n",
      "{'C': 10,\n",
      " 'class_weight': None,\n",
      " 'dual': False,\n",
      " 'fit_intercept': True,\n",
      " 'intercept_scaling': 1,\n",
      " 'l1_ratio': None,\n",
      " 'max_iter': 1000,\n",
      " 'multi_class': 'deprecated',\n",
      " 'n_jobs': -1,\n",
      " 'penalty': 'l2',\n",
      " 'random_state': 42,\n",
      " 'solver': 'lbfgs',\n",
      " 'tol': 0.0001,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "------------------------------------------------------------\n",
      "🧠 MLPClassifier\n",
      "{'activation': 'relu',\n",
      " 'alpha': 0.01,\n",
      " 'batch_size': 'auto',\n",
      " 'beta_1': 0.9,\n",
      " 'beta_2': 0.999,\n",
      " 'early_stopping': False,\n",
      " 'epsilon': 1e-08,\n",
      " 'hidden_layer_sizes': [50],\n",
      " 'learning_rate': 'constant',\n",
      " 'learning_rate_init': 0.001,\n",
      " 'max_fun': 15000,\n",
      " 'max_iter': 1000,\n",
      " 'momentum': 0.9,\n",
      " 'n_iter_no_change': 10,\n",
      " 'nesterovs_momentum': True,\n",
      " 'power_t': 0.5,\n",
      " 'random_state': 42,\n",
      " 'shuffle': True,\n",
      " 'solver': 'adam',\n",
      " 'tol': 0.0001,\n",
      " 'validation_fraction': 0.1,\n",
      " 'verbose': False,\n",
      " 'warm_start': False}\n",
      "------------------------------------------------------------\n",
      "🧠 Perceptron\n",
      "{'alpha': 0.0001,\n",
      " 'class_weight': None,\n",
      " 'early_stopping': False,\n",
      " 'eta0': 1.0,\n",
      " 'fit_intercept': True,\n",
      " 'l1_ratio': 0.15,\n",
      " 'max_iter': 1000,\n",
      " 'n_iter_no_change': 5,\n",
      " 'n_jobs': -1,\n",
      " 'penalty': None,\n",
      " 'random_state': 42,\n",
      " 'shuffle': True,\n",
      " 'tol': 0.001,\n",
      " 'validation_fraction': 0.1,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "------------------------------------------------------------\n",
      "🧠 QuadraticDiscriminantAnalysis\n",
      "{'priors': None, 'reg_param': 0.1, 'store_covariance': False, 'tol': 0.0001}\n",
      "------------------------------------------------------------\n",
      "🧠 RandomForestClassifier\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': 20,\n",
      " 'max_features': 'sqrt',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'monotonic_cst': None,\n",
      " 'n_estimators': 50,\n",
      " 'n_jobs': -1,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "------------------------------------------------------------\n",
      "🧠 RidgeClassifier\n",
      "{'alpha': 1.0,\n",
      " 'class_weight': None,\n",
      " 'copy_X': True,\n",
      " 'fit_intercept': True,\n",
      " 'max_iter': None,\n",
      " 'positive': False,\n",
      " 'random_state': 42,\n",
      " 'solver': 'auto',\n",
      " 'tol': 0.0001}\n",
      "------------------------------------------------------------\n",
      "🧠 SGDClassifier\n",
      "{'alpha': 0.0001,\n",
      " 'average': False,\n",
      " 'class_weight': None,\n",
      " 'early_stopping': False,\n",
      " 'epsilon': 0.1,\n",
      " 'eta0': 0.0,\n",
      " 'fit_intercept': True,\n",
      " 'l1_ratio': 0.15,\n",
      " 'learning_rate': 'optimal',\n",
      " 'loss': 'hinge',\n",
      " 'max_iter': 1000,\n",
      " 'n_iter_no_change': 5,\n",
      " 'n_jobs': -1,\n",
      " 'penalty': 'l1',\n",
      " 'power_t': 0.5,\n",
      " 'random_state': 42,\n",
      " 'shuffle': True,\n",
      " 'tol': 0.001,\n",
      " 'validation_fraction': 0.1,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "------------------------------------------------------------\n",
      "🧠 SVC\n",
      "{'C': 10,\n",
      " 'break_ties': False,\n",
      " 'cache_size': 200,\n",
      " 'class_weight': None,\n",
      " 'coef0': 0.0,\n",
      " 'decision_function_shape': 'ovr',\n",
      " 'degree': 3,\n",
      " 'gamma': 'scale',\n",
      " 'kernel': 'rbf',\n",
      " 'max_iter': -1,\n",
      " 'probability': True,\n",
      " 'random_state': 42,\n",
      " 'shrinking': True,\n",
      " 'tol': 0.001,\n",
      " 'verbose': False}\n",
      "------------------------------------------------------------\n",
      "🧠 XGBClassifier\n",
      "{'base_score': None,\n",
      " 'booster': None,\n",
      " 'callbacks': None,\n",
      " 'colsample_bylevel': None,\n",
      " 'colsample_bynode': None,\n",
      " 'colsample_bytree': None,\n",
      " 'device': None,\n",
      " 'early_stopping_rounds': None,\n",
      " 'enable_categorical': False,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'feature_types': None,\n",
      " 'feature_weights': None,\n",
      " 'gamma': None,\n",
      " 'grow_policy': None,\n",
      " 'importance_type': None,\n",
      " 'interaction_constraints': None,\n",
      " 'learning_rate': 0.2,\n",
      " 'max_bin': None,\n",
      " 'max_cat_threshold': None,\n",
      " 'max_cat_to_onehot': None,\n",
      " 'max_delta_step': None,\n",
      " 'max_depth': 6,\n",
      " 'max_leaves': None,\n",
      " 'min_child_weight': None,\n",
      " 'missing': nan,\n",
      " 'monotone_constraints': None,\n",
      " 'multi_strategy': None,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': -1,\n",
      " 'num_parallel_tree': None,\n",
      " 'objective': 'binary:logistic',\n",
      " 'random_state': 42,\n",
      " 'reg_alpha': None,\n",
      " 'reg_lambda': None,\n",
      " 'sampling_method': None,\n",
      " 'scale_pos_weight': None,\n",
      " 'subsample': 1.0,\n",
      " 'tree_method': None,\n",
      " 'use_label_encoder': False,\n",
      " 'validate_parameters': None,\n",
      " 'verbosity': None}\n",
      "------------------------------------------------------------\n",
      "\n",
      "Saved model_dict to: C:\\Misc\\ml_benchmark\\outputs\\tuned_models\\model_dict.joblib\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# 3. INSTANTIATE MODELS FROM TUNING RESULTS\n",
    "# -------------------------------------------\n",
    "\n",
    "# This code transforms the abstract tuning results (JSON parameter values) into\n",
    "# ready-to-use model objects. The results are the actual models ready for benchmark comparison.\n",
    " \n",
    "# Instantiate all 16 classification models, using either their tuned\n",
    "# hyperparameters (from best_params.json) created in the prior module,\n",
    "# or their default settings (e.g., GaussianNB). \n",
    "# Store this info in model_dict for each models evaluation in the next module.\n",
    "\n",
    "\n",
    "from joblib import dump\n",
    "from pprint import pprint\n",
    "\n",
    "model_dict = {}\n",
    "\n",
    "print(\"Building model_dict from best_params.json...\\n\")\n",
    "\n",
    "for model_name, meta in AVAILABLE_MODELS.items():\n",
    "    model_class_str = meta[\"class\"]\n",
    "    module_str = meta[\"module\"]\n",
    "\n",
    "    # Dynamically import and instantiate each model class.\n",
    "    # Eliminates the need for 16 separate hardcoded imports and instantiation blocks.\n",
    "    module = importlib.import_module(module_str)\n",
    "    model_class = getattr(module, model_class_str)\n",
    "\n",
    "    # Use tuned parameters if they were generated, else use default.\n",
    "    # Merge default_params with tuned best_params (i.e., the winner from the GridSearchCV). \n",
    "    default_params = meta.get(\"default_params\", {})\n",
    "    tuned_params = best_params.get(model_name, {}).get(\"best_params\", {})\n",
    "    params = {**default_params, **tuned_params}\n",
    "\n",
    "    comment = (\n",
    "        \"✅ Tuned + default params used\"\n",
    "        if tuned_params else\n",
    "        \"⚠️ Only default parameters used (no tuning found)\"\n",
    "    )\n",
    "    # Instantiate and store each model in model_dict.  \n",
    "    model = model_class(**params)\n",
    "    model_dict[model_name] = model\n",
    "\n",
    "    print(f\"{model_name.ljust(30)} | {comment}\")\n",
    "\n",
    "# Print its keys to confirm that the dictionary, model_dict, is populated\n",
    "print(\"\\nmodel_dict created with the following keys:\")\n",
    "model_keys = list(model_dict.keys())\n",
    "\n",
    "for i in range(0, len(model_keys), 4):\n",
    "    print(\"   \" + \" | \".join(model_keys[i:i+4]))\n",
    "\n",
    "\n",
    "   \n",
    "from pprint import pprint\n",
    "\n",
    "# Displays the complete parameter configuration for each instantiated model\n",
    "# using scikit-learn's .get_params() method.\n",
    "# Show ALL parameters the model will use during training/testing - not just the ones \n",
    "# explicitly set, but also all the scikit-learn defaults. Helps traceability and \n",
    "# provides documentation of the benchmarking setup.\n",
    "\n",
    "print(\"\\nConfirm full constructor parameters for each model in model_dict:\\n\")\n",
    "\n",
    "for model_name in sorted(model_dict.keys()):\n",
    "    print(f\"🧠 {model_name}\")\n",
    "    model = model_dict[model_name]\n",
    "    pprint(model.get_params())\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Create the complete dictionary of instantiated, configured models to disk \n",
    "# using joblib. The model_dict.joblib file becomes the primary input for the next step in\n",
    "# this benchmarking project. The file provides a clean separation between hyperparameter\n",
    "# optimization and subsequent model benchmarking script. Hey, saves a little RAM, too.\n",
    "\n",
    "dump(model_dict, MODEL_DICT_PATH)\n",
    "print(f\"\\nSaved model_dict to: {MODEL_DICT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969ad50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model instantiations that will be used (showing only scikt-learn's subset, not all actual params):\n",
      "\n",
      "\"AdaBoostClassifier\": AdaBoostClassifier(n_estimators=100, random_state=42)\n",
      "\"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=42)\n",
      "\"ExtraTreesClassifier\": ExtraTreesClassifier(min_samples_split=5, n_jobs=-1, random_state=42)\n",
      "\"GaussianNB\": GaussianNB()\n",
      "\"GradientBoostingClassifier\": GradientBoostingClassifier(max_features='sqrt', random_state=42, subsample=0.8)\n",
      "\"KNeighborsClassifier\": KNeighborsClassifier(metric='euclidean', n_jobs=-1, n_neighbors=7,\n",
      "                     weights='distance')\n",
      "\"LinearDiscriminantAnalysis\": LinearDiscriminantAnalysis()\n",
      "\"LogisticRegression\": LogisticRegression(C=10, max_iter=1000, n_jobs=-1, random_state=42)\n",
      "\"MLPClassifier\": MLPClassifier(alpha=0.01, hidden_layer_sizes=[50], max_iter=1000,\n",
      "              random_state=42)\n",
      "\"Perceptron\": Perceptron(n_jobs=-1, random_state=42)\n",
      "\"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(reg_param=0.1)\n",
      "\"RandomForestClassifier\": RandomForestClassifier(max_depth=20, n_estimators=50, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "\"RidgeClassifier\": RidgeClassifier(random_state=42)\n",
      "\"SGDClassifier\": SGDClassifier(n_jobs=-1, penalty='l1', random_state=42)\n",
      "\"SVC\": SVC(C=10, probability=True, random_state=42)\n",
      "\"XGBClassifier\": XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, feature_weights=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=100, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# 4. DISPLAY EACH MODEL'S HYPERPARAMETERS\n",
    "# -------------------------------------------\n",
    "\n",
    "print(\"\\nModel instantiations that will be used (showing only scikt-learn's subset, not all actual params):\\n\")\n",
    "\n",
    "for key in sorted(model_dict.keys()):\n",
    "    model = model_dict[key]\n",
    "    print(f'\"{key}\": {model}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
